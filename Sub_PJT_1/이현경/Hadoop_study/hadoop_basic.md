## **1. 대용량 자료를 빠르게 lookup해야 하는 일이 있습니다. (100GB 이상, 100ms언더로 특정자료 찾기). 어떤 백엔드를 사용하시겠나요? 느린 백엔드를 사용한다면 이를 보완할 방법은 뭐가 있을까요?**

> 이거슨 그냥 하둡/ 분산처리를 묻는 문제인거 같다..

### **분산 컴퓨팅이란?**

> 분산 컴퓨팅(distributed computing)은 분산 시스템(distributed systems)을 연구하는 컴퓨터 과학의 한 분야로, 인터넷에 연결된 여러 컴퓨터들의 처리 능력을 이용하여 메시지를 하나에서 다른 하나로 보냄(message passing)으로써 거대한 계산 문제를 해결하려는 분산처리 모델이다.- wikipedia 분산컴퓨팅

- 분산 시스템은 네트워크로 이루어진 컴퓨터들의 그룹이며, 업무를 위해 공통의 목표를 가지고 있다. [병행 컴퓨팅](https://ko.wikipedia.org/wiki/%EB%B3%91%ED%96%89_%EC%BB%B4%ED%93%A8%ED%8C%85), [병렬 컴퓨팅](https://ko.wikipedia.org/wiki/%EB%B3%91%EB%A0%AC_%EC%BB%B4%ED%93%A8%ED%8C%85), 분산 컴퓨팅은 서로 겹치는 부분이 많으며 이들 중 분명한 차이가 존재하지는 않는다.
- 병렬 분산 알고리즘
    - Scale-out
        - 아주 많은 값싼 서버들을 이용
    - Scale-up
        - 적은 수의 값비싼 서버들을 이용
    - 데이터 중신(data-intensive) 어플리케이션 분야에서는 아주 많은 값싼 서버들을 많이 이용하는 것을 선호
        - 고가의 서버들은 가격에 관점에서는 선형으로 성능이 증가하지 않기 때문이다
    - Data-intensive Processing
        - 데이터 중심 프로세싱
        - 한대의 컴퓨터의 능력으로 처리 어려움
        - 근복적으로 수십대, 수백대 혹은 수천대의 컴퓨터를 묶어서 처리하게 된다
            - 이것이 MapReduce 프레임워크가 하는 일
        - 사실상 한 개의 머신에서는 sequnetial하게 코드가 작동하지만, 여러 대에 분산해서 처리하게 되면
        데이터가 병렬로 처리되는 것 처럼 보이게 된다. (병렬로 처리된다)

**Keyword는 '대용량'**

## **MapReduce 알고리즘**

### **Mapping**

- 인풋 데이터를 가공하여 데이터를 연관성 있는 데이터들로 분류하는 작업
    - key, value의 형태로 분류된다
    - map함수는 여러 머신에 같은 key를 가진 데이터를 같은 머신으로 보낸다
- 데이터의 여러 partition에 병렬 분산으로 호출되어 수행된다
- 각 머신마다 수행된 Mapper -> 입력 데이터의 한 줄 마다 맵 함수를 호출

### **Shuffling**

- 모든 머신에서 맵 페이즈가 끝나면 시작 됨
- 맵 페이즈에서 각각의 머신으로 보내진 데이터를 Key를 이용하여 정렬하고, 뷴류한다

### **Reducing**

- 모든 머신에서 셔플링 페이즈가 다 끝나면 시작 됨
- Map에서 출력된 데이터에서 중복 데이터를 제거하고 원하는 데이터를 합산, 추출하는 작업
- 만들어진 결과물은 일반적으로 HDFS에 저장된다

## **그렇다면 사용해야할 백엔드**

> "매일 증가하는 데이터를 효율적으로 처리하고 중단 없이 다루기 위한 기술적 도전"거대한 시스템과 데이터를 '안정적'으로 만드는 개발자들 https://brunch.co.kr/@andkakao/122

### **Hadoop**

> 분산형 컴퓨팅 플랫폼

- 맵리듀스 프레임워크의 우수한 구현의 형태
- 하둡과 스파크 모두 빅데이터 처리를 위한 프레임워크라는 공통점이 있지만, 두 개의 용도에는 차이가 있음
- 하둡은 분형 파일 시스템인 HDFS와 분산형 파일 처리 시스템인 맵리듀스를 제공한다.
    - 대량의 데이터를 단일 서버에서 각각 로컬 연산 및 저장 기능을 제공하는 장비로 Scale up 가능
    - 비용 절감...
- 즉, 대량의 데이터를 서버 클러스 내 복수의 노드들에 분산시키는 역할
- 그러나 느리다

### **Spark**

> 대규모 처리를 위한 고속 일반 엔진

- 풍부한 라이브러리.. 를 탑재한 데이터 프로세싱 툴
- 분산형 스토리지로서의 역할 수행 X
- 데이터의 가공과 처리가 실시간으로 이루어져야 할 때에 필수적이다
    - 예를 들어, 스트리밍 데이터를 처리하거나, 일부 머신러닝 알고리즘의 경우
    - 실시간 마케팅... 온라인 상품 추천 등...
- 데이터 처리량이 높다

### **Kafka**

> Apache Kafka는 실시간으로 기록 스트림을 게시, 구독, 저장 및 처리할 수 있는 분산 데이터 스트리밍 플랫폼

- 하둡과 연동하여 활용하게 되는 경우가 많음
- 실시간 데이터 분석을 위해 사용하는 기술
- 스파크랑 유사하지만 조금 더 손쉽게 데이터의 가공, 처리가 가능하게 해준다는 장점이 있는 것 같음

## **느린 백엔드를 사용한다면 보완 방법은?**

> 여긴 잘 모르겠습니다.. 만...

### **redis (확실하지 않음)**

> 시스템에 새로운 구성 요소인 캐싱을 도입하는 것시스템 메모리를 사용하는 키-값 데이터 스토어

- 캐실을 구현하는 가장 일반적인 방법은 Redis가 있다.
- 모든 데이터를 메모리로 불러와서 처리하는 메모리 기반 DBMS

### **기타 의견**

- ~~그냥 데이터를 조금만 사용하자~~
- ~~데이터세트를 미리 전처리하여 확인해야하는 데이터의 수를 줄여보자..~~
- ~~프론트엔드에서 데이터를 최적화한다...?????~~

ref.s
10만명 접속을 허용하는 시스템 만들기  [https://brunch.co.kr/@jowlee/102](https://brunch.co.kr/@jowlee/102)

[https://ko.wikipedia.org/wiki/%EB%B6%84%EC%82%B0_%EC%BB%B4%ED%93%A8%ED%8C%85](https://ko.wikipedia.org/wiki/%EB%B6%84%EC%82%B0_%EC%BB%B4%ED%93%A8%ED%8C%85)

아파치 스파크 vs 아파치 하둡 [https://www.ciokorea.com/news/27798](https://www.ciokorea.com/news/27798)

MapReduce [https://velog.io/@kimdukbae/MapReduce](https://velog.io/@kimdukbae/MapReduce)